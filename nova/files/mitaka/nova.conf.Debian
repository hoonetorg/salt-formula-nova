{%- from "nova/map.jinja" import controller with context -%}
{%- from "nova/map.jinja" import compute with context -%}

{%- set server = {} %}
{%- if controller.get('enabled', False) %}
  {%- do server.update(controller) %}
{%- endif %}
{%- if compute.get('enabled', False) %}
  {%- do server.update(compute) %}
{%- endif %}
#{# server|json#}
  

[DEFAULT]
#l141(only_controller)
my_ip={{ server.bind.private_address }}
#l192
state_path = /var/lib/nova
#l255
report_interval = 5
#l265
enabled_apis = osapi_compute,metadata
#l271(only_controller)
osapi_compute_listen={{ server.bind.private_address }}
#l280(only_controller)
osapi_compute_workers = {{ server.workers }}
#l288(only_controller)
metadata_listen={{ server.bind.private_address }}
#l297(only_controller)
metadata_workers = {{ server.workers }}
#l328(only_compute)
service_down_time = 90
#l350(only_controller)
rootwrap_config = /etc/nova/rootwrap.conf
#l380
auth_strategy = keystone
#l430
use_neutron = True
#l461(only_compute)
resume_guests_state_on_host_boot = True
#l492(only_compute)
live_migration_retry_count = 30
#l514
block_device_allocate_retries=600
#l555
block_device_allocate_retries_interval=10
#l531(only_compute)
heal_instance_info_cache_interval = {{ server.heal_instance_info_cache_interval }}
#duplicate#heal_instance_info_cache_interval = 0
#l621(only_compute)
{%- if server.reserved_host_memory_mb is defined %}
reserved_host_memory_mb = {{ server.reserved_host_memory_mb }}
{%- endif %}
#l645(only_controller)
cpu_allocation_ratio = {{ server.cpu_allocation_ratio }}
#l653(only_controller)
ram_allocation_ratio = {{ server.ram_allocation_ratio }}
#l665(only_controller)
disk_allocation_ratio = {{ server.disk_allocation_ratio }}
#l701
allow_resize_to_same_host = True
#was duplicate in template#allow_resize_to_same_host=True
#l965(only_controller)
{% if server.get('scheduler_default_filters', False) %}
scheduler_default_filters = {{ server.scheduler_default_filters }}
{% endif %}
#l1070(only_controller)
scheduler_driver = filter_scheduler
#l1419
compute_driver = libvirt.LibvirtDriver
#l1483(only_compute)
{%- if server.glance.use_cow is defined %}
use_cow_images = {{ server.glance.use_cow }}
{%- endif %}
#l1511(only_controller)
vif_plugging_is_fatal = False
#l1532(only_controller)
vif_plugging_timeout = 0
#l1559
firewall_driver = nova.virt.firewall.NoopFirewallDriver
#duplicate on nova.conf for controller#firewall_driver = nova.virt.firewall.NoopFirewallDriver
#l1611(only_controller)
injected_network_template = /usr/share/nova/interfaces.template
#l1627
api_paste_config=/etc/nova/api-paste.ini
#l1737
dhcpbridge_flagfile = /etc/nova/nova.conf
#l1746
dhcpbridge = /usr/bin/nova-dhcpbridge
#l1884
force_dhcp_release = True
#l1929(only_compute)
image_cache_manager_interval = 0
#l1949
{%- if server.debug %}
debug = True
{%- else %}
debug = False
{%- endif %}
#l1955
verbose = True
#l1980
log_dir = /var/log/nova
#l2075
rpc_cast_timeout = 30
#deprecated in favor of executor_thread_pool_size(only_controller)
#rpc_thread_pool_size = 70
#l2105
executor_thread_pool_size = 70
#l2108
rpc_response_timeout = 3600
#l2117(only_controller)
rpc_backend = rabbit

#whole if clause: (only_compute)
{% if pillar.ceilometer is defined %}
instance_usage_audit = True
instance_usage_audit_period = hour
notify_on_state_change = vm_and_task_state
{% endif %}

#must be deprecated
#moved to cinder?
#(only_controller)
#volumes_dir = /etc/nova/volumes
#(only_compute)
#volumes_path=/var/lib/nova/volumes
#(only_controller)
#osapi_volume_listen={{ server.bind.private_address }}
#iscsi_helper=tgtadm
#?
#libvirt_nonblocking = True
#connection_type = libvirt
#root_helper=sudo nova-rootwrap /etc/nova/rootwrap.conf
#(only_controller)
#removed in 2013#https://github.com/openstack/nova/commit/c21cbe8cd59bffe9b3d1fe9d9f4a8dc3da8cf313
#start_guests_on_host_boot=true
#(only_controller)
#deprecated in favor of [glance]:host
#glance_host = {{ server.glance.host }}
#(only_compute)
#deprecated in favor of [glance]:port
#glance_port = 9292
#(only_compute)
#deprecated in favor of [libvirt]:live_migration_flag
#{%- if server.ceph.ephemeral is defined %}
#live_migration_flag="VIR_MIGRATE_UNDEFINE_SOURCE,VIR_MIGRATE_PEER2PEER,VIR_MIGRATE_LIVE,VIR_MIGRATE_PERSIST_DEST,VIR_MIGRATE_TUNNELLED"
#{%- else %}
#live_migration_flag=VIR_MIGRATE_UNDEFINE_SOURCE,VIR_MIGRATE_PEER2PEER,VIR_MIGRATE_LIVE
#{%- endif %}
#(only_controller)
#deprecated in favor of [neutron]:metadata_proxy_shared_secret
#{%- if server.get('networking', 'default') != "contrail" %}
#neutron_metadata_proxy_shared_secret={{ server.metadata.password }}
#{%- endif %}
#(only_compute)
#deprecated in favor of [neutron]:timeout
#neutron_url_timeout = 300

#whole section !!!!FIXME !!! attention: (only_controller)
[api_database]
#l2166
connection = {{ server.database.engine }}+pymysql://{{ server.database.user }}:{{ server.database.password }}@{{ server.database.host }}/{{ server.database.name }}_api
#l2182
idle_timeout = 180
#l2185
max_pool_size = 700
#l2189
max_retries = -1
#l2192
retry_interval = 5
#l2195
max_overflow = 100
#l2199
connection_debug = 10
#l2205
pool_timeout = 120

#not existing in api_database
#min_pool_size = 100
#db_max_retries = 3
#db_retry_interval = 1



[cache]
{%- if server.cache is defined %}
#l2260
enabled = true
#wrong option in [cache] section
#memcached_servers={%- for member in server.cache.members %}{{ member.host }}:11211{% if not loop.last %},{% endif %}{%- endfor %}
#l2270
memcache_servers={%- for member in server.cache.members %}{{ member.host }}:11211{% if not loop.last %},{% endif %}{%- endfor %}
{%- endif %}


[cinder]
#l2995
catalog_info=volumev2:cinderv2:internalURL
#l3002
{%- if server.get('identity', {}).get('region', False) %}
os_region_name = {{ server.identity.region }}
{%- endif %}

#whole section !!!!FIXME !!! attention: (only_controller)
[conductor]
#l3044
workers = {{ server.workers }}

#whole section !!!!FIXME !!! attention: (only_controller)
[database]
#l3126 and l3223
connection = {{ server.database.engine }}+pymysql://{{ server.database.user }}:{{ server.database.password }}@{{ server.database.host }}/{{ server.database.name }}
#l3142 and l3239
idle_timeout = 180
#l3147 and l3242
min_pool_size = 100
#l3152 and l3249
max_pool_size = 700
#l3158 and l3255
max_retries = -1
#l3163 and l3260
retry_interval = 5
#l3168 and l3265
max_overflow = 100
#l3173 and l3270
connection_debug = 10
#l3181 and l3278
pool_timeout = 120
#l3188 and l3285
db_retry_interval = 1
#l3200 and l3297
db_max_retries = 3

[glance]
#l3330
host = {{ server.glance.host }}
#l3338(only_compute)
port = 9292
#l3359(only_compute)
num_retries = 10

[keystone_authtoken]
#l3527
auth_uri=http://{{ server.identity.host }}:5000
#not in template
auth_url=http://{{ server.identity.host }}:35357
#correct name seems to be signing_dir(only_compute)
#signing_dirname=/tmp/keystone-signing-nova
#l3564
signing_dir=/tmp/keystone-signing-nova
{%- if server.cache is defined %}
#l3569
memcached_servers={%- for member in server.cache.members %}{{ member.host }}:11211{% if not loop.last %},{% endif %}{%- endfor %}
{%- endif %}
#l3580
revocation_cache_time = 10
#l3618
auth_type = password
#not in template
user_domain_id = {{ server.identity.get('domain', 'default') }}
project_domain_id = {{ server.identity.get('domain', 'default') }}
project_name = {{ server.identity.tenant }}
username = {{ server.identity.user }}
password = {{ server.identity.password }}

[libvirt]
#l3672
virt_type = kvm
#l3686
inject_partition = -1
#l3689
use_usb_tablet = True
#l3707(only_compute)
{%- if server.ceph.ephemeral is defined %}
live_migration_flag="VIR_MIGRATE_UNDEFINE_SOURCE,VIR_MIGRATE_PEER2PEER,VIR_MIGRATE_LIVE,VIR_MIGRATE_PERSIST_DEST,VIR_MIGRATE_TUNNELLED"
{%- else %}
live_migration_flag=VIR_MIGRATE_UNDEFINE_SOURCE,VIR_MIGRATE_PEER2PEER,VIR_MIGRATE_LIVE
{%- endif %}
#l3778
cpu_mode = host-passthrough
#l3886
use_virtio_for_bridges = True

#whole if clause: (only_compute)
{%- if server.ceph.ephemeral is defined %}
#l3831
images_type=rbd
#l3842
images_rbd_pool={{ server.ceph.rbd_pool }}
#l3845
images_rbd_ceph_conf=/etc/ceph/ceph.conf
#l3921
rbd_user={{ server.ceph.rbd_user }}
#l3924
rbd_secret_uuid={{ server.ceph.secret_uuid }}
#deprecated: should be inject_password
#libvirt_inject_password=false
#l3679
inject_password=false
#deprecated: should be inject_key
#libvirt_inject_key=false
#l3682
inject_key=false
#deprecated: should be inject_partition
#libvirt_inject_partition=-2
#l3686
inject_partition=-2
{%- endif %}

[neutron]
#l4135(only_controller)
service_metadata_proxy=True
#l4138(only_controller)
{%- if server.get('networking', 'default') != "contrail" %}
metadata_proxy_shared_secret={{ server.metadata.password }}
{%- endif %}

#l4145
url=http://{{ server.network.host }}:{{ server.network.port }}
#l4161
auth_url = http://{{ server.identity.host }}:{{ server.identity.port }}
#l4165
auth_type = password
#l4205
project_domain_name = default
#l4223(only_compute)
timeout = 300
#l4232
user_domain_name = default


#whole if clause until else FIXME: (only_controller)
#controller has probably neutron pillar
#i think: don't do that (depending on pillar of other formula, we don't do it anywhere else
{% if pillar.neutron is defined %}
#l4148
{%- if pillar.neutron.get('server', {}).get('identity', {}).get('region', False) %}
region_name= {{ pillar.neutron.server.identity.region }}
{%- endif %}
#l4199
password={{ pillar.neutron.server.identity.password }}
#l4213
project_name={{ pillar.neutron.server.identity.tenant }}
#l4239
username={{ pillar.neutron.server.identity.user }}
{%- else %}


#l4148
{%- if server.get('network', {}).get('region', False) %}
region_name= {{ server.network.region }}
{%- endif %}
#l4199
password={{ server.network.identity.password }}
#l4213
project_name={{ server.network.identity.tenant }}
#l4239
username={{ server.network.identity.user }}
{%- endif %}(only_controller)

[oslo_concurrency]
#l4296
lock_path = /var/lib/nova/tmp


#whole section !!!!FIXME !!! attention: (only_compute)
[oslo_messaging_notifications]
{%- if server.notification is defined %}
#l4379
driver = messagingv2
{%- endif %}

[oslo_messaging_rabbit]
{%- if server.message_queue.members is defined %}
#l4457
rabbit_hosts = {% for member in server.message_queue.members -%}
                   {{ member.host }}:{{ member.get('port', 5672) }}
                   {%- if not loop.last -%},{%- endif -%}
               {%- endfor -%}
{%- else %}
#l4447
rabbit_host = {{ server.message_queue.host }}
#l4453
rabbit_port = {{ server.message_queue.port }}
{%- endif %}
#l4465
rabbit_userid = {{ server.message_queue.user }}
#l4469
rabbit_password = {{ server.message_queue.password }}
#l4477
rabbit_virtual_host = {{ server.message_queue.virtual_host }}

#FIXMEseems to be in [default] section which must be wrong #l2044
rpc_conn_pool_size = 300

#l4480
rabbit_retry_interval = 1
#l4485
rabbit_retry_backoff = 2

[spice]
#l4850
html5proxy_base_url = {{ server.vncproxy_url }}/spice_auto.html
#l4860
enabled = false

[vnc]
#l5374
enabled = true
#l5397
keymap = {{ server.get('vnc_keymap', 'en-us') }}

#according to https://ask.openstack.org/en/question/67409/does-it-make-sense-to-define-a-vnc-server-in-an-openstack-controller-node/
#only needed on compute node
#l5416
vncserver_listen={{ server.bind.private_address }}
#l5440
vncserver_proxyclient_address={{ server.bind.private_address }}


#l5466(only_controller)
novncproxy_host = 0.0.0.0
#l5494
novncproxy_port={{ server.bind.get('vnc_port', '6080') }}
#l5521
novncproxy_base_url = {{ server.vncproxy_url }}/vnc_auto.html
